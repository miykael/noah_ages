{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create other 'everyday' NFTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import cv2\n",
    "from skimage.transform import resize, rescale\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare images\n",
    "\n",
    "The aligned photos are all in 4k resolution. That is too much detail for a 'quick' data exploration. Therefore, this step is trying to find a reasonable downsampling resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all images\n",
    "imgs = sorted(glob(\"img_small/20*\"))\n",
    "\n",
    "print(f\"We found {len(imgs)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First and last photo\n",
    "imgs[0], imgs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Months total\n",
    "n_months = 21*12+4\n",
    "n_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the last of these images\n",
    "last_img = imageio.imread(imgs[-1])\n",
    "plt.imshow(last_img)\n",
    "print(\n",
    "    f\"Each image has the shape {last_img.shape}, where the last dimension are the 3 RGB color channels.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning models love a lot of data, but images in 4k resolution might nonetheless push it a bit. So let's resize this to something a bit more compact and let's make the image shape squared. This is not really required, just a data science habbit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image height and width\n",
    "height, width = last_img.shape[:2]\n",
    "\n",
    "# Crop image to a squared shape, centered in the middle\n",
    "offset = int((width - height) / 3.5)\n",
    "img_squared = last_img[:, offset:-offset, :]\n",
    "\n",
    "# Plot the cropped image version\n",
    "plt.imshow(img_squared);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore different resizing shapes\n",
    "resolutions = [1/i for i in range(1, 5)]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(resolutions), figsize=(3 * len(resolutions), 4))\n",
    "for i, res in enumerate(resolutions):\n",
    "    new_img = rescale(img_squared, res, anti_aliasing=True, multichannel=True)\n",
    "    axes[i].set_title(f\"Resolution: {np.round(res, 3)} {new_img.shape}\")\n",
    "    axes[i].imshow(new_img, interpolation='nearest')\n",
    "    axes[i].axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "64 x 64 pixels is definitely too small. Let's go with 256 for now. As the following image shows, the resolution is good enough to see some smallish details, but also small enough to keep the data dimension (256 * 256 * 3 = 196,608 pixel values) to something almost 'manageable'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 1/3.\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(rescale(img_squared, res, anti_aliasing=True, multichannel=True));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we have explored all this. Let's go ahead and preapre the whole dataset. We will take the aligned 4k photos, crop the images to a square and downsize them to 256 x 256 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder for AI prepared images\n",
    "out_dir = \"img_AI_NFT\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Define image resolution\n",
    "res = 1/3.\n",
    "\n",
    "# Prepare images and store them in new folder\n",
    "for i in tqdm(range(len(imgs))):\n",
    "\n",
    "    # Define file output name\n",
    "    out_file = os.path.join(out_dir, f\"img_{i+1:04d}.png\")\n",
    "\n",
    "    # Create image if it doesn't yet exist\n",
    "    if not os.path.exists(out_file):\n",
    "\n",
    "        # Â Transform image\n",
    "        img = (\n",
    "            255 * rescale(imageio.imread(imgs[i])[:, offset:-offset, :],\n",
    "                          res, anti_aliasing=True, multichannel=True)\n",
    "        ).astype(\"uint8\")\n",
    "\n",
    "        # Store transformed file\n",
    "        imageio.imwrite(out_file, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load dataset (and have some fun)\n",
    "\n",
    "Now that the data is prepared and stored on the hard drive, let's load all of it into memory and have some fun with some data exploration :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array(\n",
    "    [imageio.imread(d) for d in tqdm(sorted(glob(os.path.join(out_dir, \"*png\"))))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Yearly average collage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = (3, 7)\n",
    "grid_points = np.prod((x, y))\n",
    "imgs_split = np.array_split(data, grid_points)\n",
    "print(len(imgs_split))\n",
    "imgs_averages = np.array([im.mean(0).astype(\"int\") for im in tqdm(imgs_split)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic = np.concatenate([np.concatenate(imgs_averages[i*x:(i+1)*x], axis=1)\n",
    "                         for i in range(y)], axis=0).astype(\"uint8\")\n",
    "mosaic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot a grid of average images\n",
    "figsize = 45\n",
    "plt.figure(figsize=(figsize/np.divide(*mosaic.shape[:2]), figsize))\n",
    "plt.imshow(mosaic)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('noah_mosaic_yearly_vertical.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = (7, 3)\n",
    "grid_points = np.prod((x, y))\n",
    "imgs_split = np.array_split(data, grid_points)\n",
    "print(len(imgs_split))\n",
    "imgs_averages = np.array([im.mean(0).astype(\"int\") for im in tqdm(imgs_split)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic = np.concatenate([np.concatenate(imgs_averages[i*x:(i+1)*x], axis=1)\n",
    "                         for i in range(y)], axis=0).astype(\"uint8\")\n",
    "mosaic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid of average images\n",
    "figsize = 45\n",
    "plt.figure(figsize=(figsize, figsize/np.divide(mosaic.shape[1], mosaic.shape[0])))\n",
    "plt.imshow(mosaic)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('noah_mosaic_yearly_horizontal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Monthly average collage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = (16, 16)\n",
    "grid_points = np.prod((x, y))\n",
    "imgs_split = np.array_split(data, grid_points)\n",
    "print(len(imgs_split))\n",
    "imgs_averages = np.array([im.mean(0).astype(\"int\") for im in tqdm(imgs_split)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic = np.concatenate([np.concatenate(imgs_averages[i*x:(i+1)*x], axis=1)\n",
    "                         for i in range(y)], axis=0).astype(\"uint8\")\n",
    "mosaic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a grid of average images\n",
    "figsize = 45\n",
    "plt.figure(figsize=(figsize/np.divide(*mosaic.shape[:2]), figsize))\n",
    "plt.imshow(mosaic)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('noah_mosaic_monthly.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Monthly but squared images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = (16, 16)\n",
    "grid_points = np.prod((x, y))\n",
    "imgs_split = np.array_split(data, grid_points)\n",
    "print(len(imgs_split))\n",
    "imgs_averages = np.array([im.mean(0).astype(\"int\") for im in tqdm(imgs_split)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_offset = imgs_averages.shape[2] - imgs_averages.shape[1]\n",
    "min_offset = min_offset // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic = np.concatenate([np.concatenate(imgs_averages[i*x:(i+1)*x, :, min_offset:-min_offset, :], axis=1)\n",
    "                         for i in range(y)], axis=0).astype(\"uint8\")\n",
    "mosaic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a grid of average images\n",
    "figsize = 45\n",
    "plt.figure(figsize=(figsize/np.divide(*mosaic.shape[:2]), figsize))\n",
    "plt.imshow(mosaic)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('noah_mosaic_monthly_squared.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Monthly average collage, row per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = (12, 21)\n",
    "grid_points = np.prod((x, y))\n",
    "imgs_split = np.array_split(data, grid_points)\n",
    "print(len(imgs_split))\n",
    "imgs_averages = np.array([im.mean(0).astype(\"int\") for im in tqdm(imgs_split)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic = np.concatenate([np.concatenate(imgs_averages[i*x:(i+1)*x], axis=1)\n",
    "                         for i in range(y)], axis=0).astype(\"uint8\")\n",
    "mosaic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a grid of average images\n",
    "figsize = 45\n",
    "plt.figure(figsize=(figsize/np.divide(*mosaic.shape[:2]), figsize))\n",
    "plt.imshow(mosaic)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('noah_mosaic_monthly_year_per_row.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Weekly average collage, row per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = (30, 37)\n",
    "grid_points = np.prod((x, y))\n",
    "imgs_split = np.array_split(data, grid_points)\n",
    "print(len(imgs_split))\n",
    "imgs_averages = np.array([im.mean(0).astype(\"int\") for im in tqdm(imgs_split)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic = np.concatenate([np.concatenate(imgs_averages[i*x:(i+1)*x], axis=1)\n",
    "                         for i in tqdm(range(y))], axis=0).astype(\"uint8\")\n",
    "mosaic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a grid of average images\n",
    "figsize = 60\n",
    "plt.figure(figsize=(figsize/np.divide(*mosaic.shape[:2]), figsize))\n",
    "plt.imshow(mosaic)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('noah_mosaic_week_30x37.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = (33, 33)\n",
    "grid_points = np.prod((x, y))\n",
    "imgs_split = np.array_split(data, grid_points)\n",
    "print(len(imgs_split))\n",
    "imgs_averages = np.array([im.mean(0).astype(\"int\") for im in tqdm(imgs_split)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_offset = imgs_averages.shape[2] - imgs_averages.shape[1]\n",
    "min_offset = min_offset // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic = np.concatenate([np.concatenate(imgs_averages[i*x:(i+1)*x, :, min_offset:-min_offset, :], axis=1)\n",
    "                         for i in tqdm(range(y))], axis=0).astype(\"uint8\")\n",
    "mosaic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a grid of average images\n",
    "figsize = 60\n",
    "plt.figure(figsize=(figsize/np.divide(*mosaic.shape[:2]), figsize))\n",
    "plt.imshow(mosaic)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('noah_mosaic_week_33x33_squared.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. 21 year in 21 seconds video - small\n",
    "\n",
    "As a homage to my first tweet about this project, let's create a gif of all alligned 7777 photos and loop through them in 21 seconds (i.e. 1 year per second). And as in the original post, let's average for each frame 60 images at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = sorted(glob(\"img_small/20*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "# Save images to disk\n",
    "out_dir = 'img_video_21s'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "n_steps = 12\n",
    "smooth = 60\n",
    "imgs_average = []\n",
    "for i in tqdm(range(len(imgs)//n_steps)):\n",
    "    img_files = imgs[i*n_steps:i*n_steps+smooth]\n",
    "    data_small = np.mean([imageio.imread(f) for f in img_files], axis=0)\n",
    "            \n",
    "    # Create out_filename\n",
    "    out_filename = os.path.join(out_dir, '%04d.jpg' % (i + 1))\n",
    "    \n",
    "    # Save composition image\n",
    "    io.imsave(out_filename, data_small.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use either code (the one that works) to create the video\n",
    "!cat img_video_21s/*jpg | ffmpeg -f image2pipe -r 30 -vcodec mjpeg -i - -vcodec libx264 video_21s_small.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dimensionality reduction\n",
    "\n",
    "To better understand how the images relate to each other, let's look at two ways of projecting the images from a high-dimensional space (i.e. 256 x 256 pixels = 65536 dimenions), down to two dimensions. To do so, we will use principal component analysis (PCA) and UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'img_AI_NFT'\n",
    "offset = 60\n",
    "data_small = np.array(\n",
    "    [imageio.imread(d)[::2, offset:-offset:2, :] / 255.0 for d in tqdm(sorted(glob(os.path.join(out_dir, \"*png\"))))]\n",
    ")\n",
    "data_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten color images\n",
    "X_small = np.reshape(data_small, (len(data_small), -1))\n",
    "X_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a supportive 'age' variable\n",
    "age = np.linspace(0, 256, len(data_small), endpoint=False, dtype=\"int\")\n",
    "age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify how many PCA components should be kept\n",
    "n_comp = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCA components\n",
    "pca_small = PCA(n_comp)\n",
    "%time X_pca_small = pca_small.fit_transform(X_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show scree plot\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(pca_small.explained_variance_ratio_.cumsum())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â How much variance is explained by first X components\n",
    "pca_small.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first two PCA components with image index color coded\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    X_pca_small[:, 0],\n",
    "    X_pca_small[:, 1],\n",
    "    c=age,\n",
    "    alpha=0.5,\n",
    "    cmap=\"Spectral\",\n",
    ")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. UMAP\n",
    "\n",
    "UMAP is another AI approach of how high-dimensional data can be projected down to just a few dimensions (here 2D). In contrast to PCA, where the dimensions are reduced into the direction of most explained variance, with UMAP, the reduction is done in such a way that the points keep the relative distance to each other.\n",
    "\n",
    "In other words, with UMAP, points in N-dimensional space that were far apart are still far apart, and points that were close are still close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP on color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute UMAP projection based on the PCA reduced features\n",
    "umap_small = UMAP(n_neighbors=15, min_dist=1)\n",
    "%time X_umap_small = umap_small.fit_transform(X_pca_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the UMAP projection\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.scatter(X_umap_small[:, 0], X_umap_small[:, 1], c=age, cmap=\"Spectral\", s=10)\n",
    "plt.colorbar()\n",
    "#plt.yticks([])\n",
    "#plt.xticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the UMAP projection with a equally spaced target grid\n",
    "x, y = (25, 25)\n",
    "grid = np.array(\n",
    "    [(i, j) for i in np.linspace(-7, 15, x) for j in np.linspace(-3, 15, y)]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.scatter(\n",
    "    X_umap_small[:, 0],\n",
    "    X_umap_small[:, 1],\n",
    "    c=np.linspace(0, 21, len(data_small)),\n",
    "    cmap=\"Spectral\",\n",
    "    s=10,\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.scatter(*grid.T, s=10, c=\"k\")\n",
    "plt.yticks([])\n",
    "plt.xticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert UMAP projection for target grid\n",
    "%time inv_umap_small = umap_small.inverse_transform(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse PCA dimensionality reduction\n",
    "faces_small = np.array(\n",
    "    [\n",
    "        p.reshape(data_small.shape[1:]).clip(min=0, max=1)\n",
    "        for p in tqdm(pca_small.inverse_transform(inv_umap_small))\n",
    "    ]\n",
    ")\n",
    "faces_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic = np.concatenate([np.concatenate(255*faces_small[i*x:(i+1)*x], axis=1)\n",
    "                         for i in range(y)], axis=0).astype(\"uint8\")\n",
    "mosaic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid of average images\n",
    "figsize = 45\n",
    "plt.figure(figsize=(figsize/np.divide(*mosaic.shape[:2]), figsize))\n",
    "plt.imshow(mosaic)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('noah_mosaic_multiverse_25x25.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
